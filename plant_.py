# -*- coding: utf-8 -*-
"""plant .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10McsYaULZfW_NckH9_GJYkbee-yXU9Pk
"""

pip install tensorflow

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
import itertools
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from google.colab import drive
import os

from google.colab import drive
drive.mount('/content/drive')

dataset_path = "/content/drive/MyDrive/DA project 2-20250328T145121Z-001/DA project 2"
img_width, img_height = 128, 128
batch_size = 32

# Load training dataset
train_ds = tf.keras.utils.image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=(img_width, img_height),
    batch_size=batch_size,
    label_mode='categorical'  # Use 'categorical' for multi-class classification
)

# Load validation dataset
val_ds = tf.keras.utils.image_dataset_from_directory(
    dataset_path,
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=(img_width, img_height),
    batch_size=batch_size,
    label_mode='categorical'
)

# Get the class names from the training dataset
class_names = train_ds.class_names

# Augmentation layer (adjust parameters as needed)
data_augmentation = tf.keras.Sequential(
    [
        tf.keras.layers.RandomFlip("horizontal"),
        tf.keras.layers.RandomRotation(0.2),
        tf.keras.layers.RandomZoom(0.2),
    ]
)

# Apply augmentation to the training dataset
def augment_data(image, label):
    image = data_augmentation(image)
    # Rescale image (if needed)
    image = tf.cast(image, tf.float32) / 255.0
    return image, label

train_ds = train_ds.map(augment_data)

# Preprocess validation dataset (only rescaling)
def preprocess_val_data(image, label):
    image = tf.cast(image, tf.float32) / 255.0  # Rescale image
    return image, label

val_ds = val_ds.map(preprocess_val_data)

# Fetch a batch of images and labels
images, labels = next(iter(train_ds))  # Using 'train_ds' directly instead of 'train_generator'

# Plot the first 10 images from the batch
plt.figure(figsize=(12, 6))
for i in range(10):
    plt.subplot(2, 5, i + 1)
    plt.imshow(images[i])
    plt.title(class_names[np.argmax(labels[i])])  # Get class label
    plt.axis('off')
plt.show()

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(img_width, img_height, 3)),
    MaxPooling2D(pool_size=(2,2)),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),

    Conv2D(256, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),

    Conv2D(512, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(class_names), activation='softmax')
])

model.summary()

model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=40
)

train_acc = history.history['accuracy'][-1]
val_acc = history.history['val_accuracy'][-1]
print(f" Training Accuracy: {train_acc:.4f}")
print(f" Validation Accuracy: {val_acc:.4f}")

# Evaluate on validation set
y_true = []
y_pred = []

for images, labels in val_ds:
    preds = model.predict(images)
    y_true.extend(np.argmax(labels.numpy(), axis=1))
    y_pred.extend(np.argmax(preds, axis=1))

print("\n Classification Report:")
print(classification_report(y_true, y_pred, target_names=class_names))

# Plot learning curves
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Accuracy', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='red')
plt.title('Accuracy over epochs')
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color='red')
plt.title('Loss over epochs')
plt.legend()
plt.show()

# Get predictions and true labels
y_true = []
y_pred_prob = []
for images, labels in val_ds:
    y_true.extend(np.argmax(labels.numpy(), axis=1))
    y_pred_prob.extend(model.predict(images))

y_pred_prob = np.array(y_pred_prob)
y_pred = np.argmax(y_pred_prob, axis=1)
y_true = np.array(y_true)

# Confusion Matrix
conf_matrix = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6,5))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Classification Report
print("Classification Report:\n", classification_report(y_true, y_pred, target_names=class_names))

# Type I & II Errors (example for binary classification or one-vs-rest)
if len(class_names) == 2:
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    print(f"\nType I Error (False Positive): {fp}")
    print(f"Type II Error (False Negative): {fn}")
else:
    print("\nType I and II error analysis is generally for binary classification. For multi-class, use per-class confusion matrix.")

# ROC Curve (micro-average for multi-class)
from sklearn.preprocessing import label_binarize
y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))
fpr, tpr, _ = roc_curve(y_true_bin.ravel(), y_pred_prob.ravel())
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label='Micro-averaged ROC curve (area = {0:0.2f})'.format(roc_auc))
plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Statistical Tests
# 1. Z-test (for large samples)
import scipy.stats as stats

mean_diff = np.mean(y_pred - y_true)
std_diff = np.std(y_pred - y_true)
z_score = mean_diff / (std_diff / np.sqrt(len(y_true)))
p_z = 2 * (1 - stats.norm.cdf(abs(z_score))) # Now 'stats' is defined
print(f"\nZ-test: z = {z_score:.3f}, p-value = {p_z:.4f}")

# 2. T-test (paired)
t_stat, p_t = stats.ttest_rel(y_pred, y_true)
print(f"T-test: t = {t_stat:.3f}, p-value = {p_t:.4f}")

# 3. Variance Test (Levene's Test)
levene_stat, p_var = stats.levene(y_pred, y_true)
print(f"Variance Test (Levene): W = {levene_stat:.3f}, p-value = {p_var:.4f}")